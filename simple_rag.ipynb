{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建一个简单的RAG\n",
    "\n",
    "目标：走一遍全流程，对RAG具体怎么实现有一个具体的认识；\n",
    "\n",
    "<img src=\"RAG.png\" alt=\"Simple RAGo\" style=\"width:550px;height:300px;\">\n",
    "<img src=\"dataPrepare.png\" alt=\"Data prepare\" style=\"width:550px;height:300px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 向量存储与检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从本地load文件数据\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, json_file_path):\n",
    "        self.json_file_path = json_file_path\n",
    "\n",
    "    def load_data(self):\n",
    "        data = json.loads(Path(self.json_file_path).read_text())\n",
    "        return data\n",
    "\n",
    "    def create_documents(self, length=None):\n",
    "        data = self.load_data()\n",
    "        if length is None:\n",
    "            length = len(data)\n",
    "        \n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=self.get_page_content(item),\n",
    "                metadata=item\n",
    "            )\n",
    "            for item in data[:length]\n",
    "        ]\n",
    "        return documents\n",
    "\n",
    "    def get_page_content(self, item):\n",
    "        return f\"{item['title']} {item['author']} {item['publication_date']} {item['description']} {' '.join(item['genres'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据向量化\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name):\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        return self.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单的”向量数据库“\n",
    "from langchain.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "\n",
    "class VectorSpaceManager:\n",
    "    def __init__(self, embedding_manager):\n",
    "        self.embedding_manager = embedding_manager\n",
    "        self.embeddings = self.embedding_manager.get_embeddings()\n",
    "\n",
    "    def create_vector_space(self, documents):\n",
    "        vector_store = FAISS.from_documents(documents[:2], self.embeddings)\n",
    "\n",
    "        with tqdm(total=len(documents), desc=\"Creating vector space\") as pbar:\n",
    "            batch_size = 100\n",
    "            for i in range(2, len(documents), batch_size):\n",
    "                batch_documents = documents[i:i+batch_size]\n",
    "                tempt_vector_store = FAISS.from_documents(batch_documents, self.embeddings)\n",
    "                vector_store.merge_from(tempt_vector_store)\n",
    "                pbar.update(len(batch_documents))\n",
    "\n",
    "        return vector_store\n",
    "\n",
    "    def save_vector_space(self, vector_store, save_path):\n",
    "        print(f\"Saving vector space to {save_path}...\")\n",
    "        vector_store.save_local(save_path)\n",
    "        print(f\"Finished!\")\n",
    "\n",
    "    def load_vector_space(self, save_path):\n",
    "        print(f\"Lodaing vector space from {save_path}\")\n",
    "        return FAISS.load_local(save_path, self.embeddings, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating vector space:  98%|█████████▊| 98/100 [00:00<00:00, 103.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vector space to data/book_vector_store...\n",
      "Finished!\n",
      "Lodaing vector space from data/book_vector_store\n",
      "here is the search results: [Document(page_content=\"A book not exist Liu Jia 2024 这是一本没有什么内容的书 Children's literature Juvenile fantasy Adventure novel Speculative fiction Fantasy Fiction\", metadata={'id': '30292', 'title': 'A book not exist', 'author': 'Liu Jia', 'publication_date': '2024', 'genres': [\"Children's literature\", 'Juvenile fantasy', 'Adventure novel', 'Speculative fiction', 'Fantasy', 'Fiction'], 'description': '这是一本没有什么内容的书'}), Document(page_content='The Pit and the Pendulum Nancy Kilpatrick 1842  The story takes place during the Spanish Inquisition. At the beginning of the story an unnamed narrator is brought to trial before various sinister judges. Poe provides no explanation of why he is there or for what he has been arrested. Before him are seven tall white candles on a table, and, as they melt, his hopes of survival also diminish. He is condemned to death and finds himself in a pitch black compartment. At first the prisoner thinks that he is locked in a tomb, but he discovers that he is in a cell. He decides to explore the cell by placing a hem from his robe against a wall so he can count the paces around the room; however, he faints before being able to measure the whole perimeter. When the prisoner awakens he discovers food and water nearby. He gets back up and tries to measure the prison again, finding that the perimeter measures one hundred steps. While crossing the room he slips on the hem of his robe. He discovers that if he had not tripped he would have walked into a deep pit with water at the bottom in the center of the cell. After losing consciousness again the narrator discovers that the prison is slightly illuminated and that he is bound to a wooden board by ropes. He looks up in horror to see a painted picture of Father Time on the ceiling; hanging from the figure is a gigantic scythe-like pendulum swinging slowly back and forth. The pendulum is inexorably sliding downwards and will eventually kill him. However the condemned man is able to attract rats to his bonds with meat left for him to eat and they start chewing through the ropes. As the pendulum reaches a point inches above his heart, the prisoner breaks free of the ropes and watches as the pendulum is drawn back to the ceiling. He then sees that the walls have become red-hot and begun moving inwards, driving him into the center of the room and towards the brink of the pit. As he gazes into the pit, he decides that no fate could be worse than falling into it. It is implied by the text that the narrator fears what he sees at the bottom of the pit, or perhaps is frightened by its depth. The exact cause of his fear is not clearly stated. However, as the narrator moves back from the pit, he sees that the red-hot walls are leaving him with no foothold. As the prisoner begins to fall into the pit, he hears human voices. The walls rush back and an arm catches him. The French Army has taken Toledo and the Inquisition is in the hands of its enemies.\\n Horror Speculative fiction Short story', metadata={'id': '30757', 'title': 'The Pit and the Pendulum', 'author': 'Nancy Kilpatrick', 'publication_date': '1842', 'genres': ['Horror', 'Speculative fiction', 'Short story'], 'description': ' The story takes place during the Spanish Inquisition. At the beginning of the story an unnamed narrator is brought to trial before various sinister judges. Poe provides no explanation of why he is there or for what he has been arrested. Before him are seven tall white candles on a table, and, as they melt, his hopes of survival also diminish. He is condemned to death and finds himself in a pitch black compartment. At first the prisoner thinks that he is locked in a tomb, but he discovers that he is in a cell. He decides to explore the cell by placing a hem from his robe against a wall so he can count the paces around the room; however, he faints before being able to measure the whole perimeter. When the prisoner awakens he discovers food and water nearby. He gets back up and tries to measure the prison again, finding that the perimeter measures one hundred steps. While crossing the room he slips on the hem of his robe. He discovers that if he had not tripped he would have walked into a deep pit with water at the bottom in the center of the cell. After losing consciousness again the narrator discovers that the prison is slightly illuminated and that he is bound to a wooden board by ropes. He looks up in horror to see a painted picture of Father Time on the ceiling; hanging from the figure is a gigantic scythe-like pendulum swinging slowly back and forth. The pendulum is inexorably sliding downwards and will eventually kill him. However the condemned man is able to attract rats to his bonds with meat left for him to eat and they start chewing through the ropes. As the pendulum reaches a point inches above his heart, the prisoner breaks free of the ropes and watches as the pendulum is drawn back to the ceiling. He then sees that the walls have become red-hot and begun moving inwards, driving him into the center of the room and towards the brink of the pit. As he gazes into the pit, he decides that no fate could be worse than falling into it. It is implied by the text that the narrator fears what he sees at the bottom of the pit, or perhaps is frightened by its depth. The exact cause of his fear is not clearly stated. However, as the narrator moves back from the pit, he sees that the red-hot walls are leaving him with no foothold. As the prisoner begins to fall into the pit, he hears human voices. The walls rush back and an arm catches him. The French Army has taken Toledo and the Inquisition is in the hands of its enemies.\\n'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 向量存储\n",
    "def process_data(json_file_path, model_name, save_path, data_loader_class, length=None):\n",
    "    # 数据向量化模型\n",
    "    embedding_manager = EmbeddingManager(model_name)\n",
    "\n",
    "    # ”向量数据库“\n",
    "    vector_space_manager = VectorSpaceManager(embedding_manager)\n",
    "\n",
    "    # 从本地加载数据\n",
    "    data_loader = data_loader_class(json_file_path)\n",
    "    documents = data_loader.create_documents(length=length)\n",
    "\n",
    "    # 调用”向量数据库“将本地数据向量化\n",
    "    vector_store = vector_space_manager.create_vector_space(documents)\n",
    "    # 存储向量化后的数据\n",
    "    vector_space_manager.save_vector_space(vector_store, save_path)\n",
    "\n",
    "    # 从”向量数据库“中查询数据\n",
    "    vector_store = vector_space_manager.load_vector_space(save_path)\n",
    "    query = \"找本划水的书\"\n",
    "    search_results = vector_store.search(query, k=2, search_type=\"similarity\")\n",
    "    print(\"here is the search results:\", search_results)\n",
    "\n",
    "# 测试用例\n",
    "if __name__ == \"__main__\":\n",
    "    # Book\n",
    "    json_file_path = 'data/BookSummaries/book.json'  # Replace with the actual JSON file path\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    save_path = 'data/book_vector_store'  # Replace with the actual save path\n",
    "    process_data(json_file_path, model_name, save_path, DataLoader, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据用户输入，检索信息提供给大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检索信息并拼接prompt\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS  \n",
    "from langchain.agents import Tool\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "class ToolManager:\n",
    "    def __init__(self, llm, books_vector_path, embeddings):\n",
    "        self.llm = llm\n",
    "        self.books_vector_path = books_vector_path\n",
    "        self.embeddings = embeddings\n",
    "        self.tools = self._initialize_tool()\n",
    "\n",
    "    def _initialize_tool(self):\n",
    "        # 链接”向量数据库“\n",
    "        books_vector_store = FAISS.load_local(self.books_vector_path, self.embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "        # 定义提示词模版\n",
    "        prompt_template = \"\"\"If the context is not relevant, \n",
    "        please answer the question by using your own knowledge about the topic\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "        PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "        # 使用RetrievalQA检索向量\n",
    "        books_qa = RetrievalQA.from_chain_type(llm=self.llm, chain_type=\"stuff\", retriever=books_vector_store.as_retriever(search_kwargs={\"k\": 3}), chain_type_kwargs={\"prompt\": PROMPT})\n",
    "\n",
    "        return {\n",
    "            \"books\": Tool(name=\"BooksTool\", func=books_qa.run, description=\"Retrieve book information.\")\n",
    "        }\n",
    "    def get_tool(self):\n",
    "       return self.tools.get(\"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提供用户交互界面 & 调用大模型\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import ConversationalChatAgent, AgentExecutor\n",
    "import time\n",
    "\n",
    "class ChatAgent:\n",
    "    def __init__(self, llm, tool_manager):\n",
    "        self.llm = llm\n",
    "        self.tool_manager = tool_manager\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"input\", return_messages=True)\n",
    "        self.agent = ConversationalChatAgent.from_llm_and_tools(llm=self.llm, tools=list(self.tool_manager.tools.values()), system_message=\"You are a smart assistant whose main goal is to recommend amazing books and movies to users. Provide helpful, **short** and concise recommendations with a touch of fun!\")\n",
    "        self.chat_agent = AgentExecutor.from_agent_and_tools(agent=self.agent, tools=list(self.tool_manager.tools.values()), verbose=True, memory=self.memory)\n",
    "\n",
    "    def get_response(self, query):\n",
    "\n",
    "        try:\n",
    "            response = self.chat_agent.run(input=query)\n",
    "        except ValueError as e:\n",
    "            response = str(e)\n",
    "\n",
    "        return {\"answer\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  配置大模型\n",
    "\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '你的key')\n",
    "llm = ChatOpenAI(openai_api_base=\"https://api.lingyiwanwu.com/v1\", openai_api_key=OPENAI_API_KEY, model=\"yi-34b-chat-0205\",temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready to talk! Type 'quit' to exit.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The Art of War by Sun Tzu\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "You: 找一本书里全是虚头巴脑的假大空的书\n",
      "Chatbot: The Art of War by Sun Tzu\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"《刘佳作品集》\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "You: 找一本刘佳写的，没啥内容的书\n",
      "Chatbot: 《刘佳作品集》\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "\n",
    "# from vector_space import EmbeddingManager\n",
    "\n",
    "# Initialize components\n",
    "book_vector_store_path = \"data/book_vector_store\"\n",
    "embeddings_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = EmbeddingManager(embeddings_model_name).get_embeddings()\n",
    "tool_manager = ToolManager(llm, book_vector_store_path,embeddings)\n",
    "chat_agent = ChatAgent(llm, tool_manager)\n",
    "\n",
    "print(\"Chatbot is ready to talk! Type 'quit' to exit.\")\n",
    "    \n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "\n",
    "    response = chat_agent.get_response(user_input)\n",
    "    print(f\"You: {user_input}\")\n",
    "    print(f\"Chatbot: {response['answer']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
